---
title: "MBI_MA_data_rev1"
author: "Sicong Liu"
date: '2022-11-06'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(message = FALSE, echo = FALSE, dpi = 300, cache.lazy = FALSE, tidy = "styler", out.width = "90%", fig.align = "center", fig.width = 10, fig.asp = 0.618, error = F, warning = F)

options(dplyr.print_min = Inf,
        tibble.width = Inf, 
        tibble.print_max = 20,
        max.print = 100000,
        digits = 8, 
        scipen = 999999)

rm(list=ls())
library(metafor)
library(robumeta)
library(clubSandwich)                      
library(tidyverse)
library(weightr)
library(ggplot2)
library(reshape2)
library(cowplot)
library(janitor)
library(bda)                               
library(lavaan)
library(ggridges)
library(ggExtra)
library(GGally)
library(viridis)
library(MASS)
library(ordinal)       
library(boot)          
library(dvmisc)        
library(hrbrthemes)   
library(patchwork)    
library(rstatix)
set.seed(55555)
select <- dplyr::select
```


```{r update_var_multi_entry_study}
######################################################################################################################################################
## This section handles the skipped questions in header/sheet1 and static/sheet2 part for multi-entry studies in the MBI database
#  - Two sets of loops: one for Main, the other for MainAux 
######################################################################################################################################################

### data parameters ---
rho <-          # prepost corr.
  "05"
  # "04"
  # "06"

### read ---
df <- read_csv(paste0("../data/mid/1_merge/Main_rho",rho,"_df_measurementES-20230205-132326.csv")) %>%                # Main
  rename(record = record.x) %>% 
  select(-record.y) %>% 
  relocate(c(behcli, sd, target), .after = studyyearend)    # aligning var order w/ df2 for convenience of updating var from multi-entry studies below (not actually used but helps check var names)
df2 <- read_csv(paste0("../data/mid/1_merge/MainAux_rho",rho,"_df_measurementES-20230205-135537.csv")) %>%            # Main + Aux
  rename(record = record.x) %>% 
  select(-record.y)

## filling in some missing values so it is easier later (see ../table/1_include/study_inclusion_criteria_summary.docx)
df[which(df$authyear=="Burke et al. 2020 MD (fall22check)"), c("hiv_recnum")] <- 1
df2[which(df2$authyear=="Burke et al. 2020 MD (fall22check)"), c("hiv_recnum")] <- 1

df[which(df$authyear=="Firestone 2016/MD (fall22check)"), c("hiv_recnum")] <- 1
df2[which(df2$authyear=="Firestone 2016/MD (fall22check)"), c("hiv_recnum")] <- 1

# ## check var name alignment
# setdiff(names(df), names(df2))
# sum(names(df) == names(df2))

# ## supervise labels for combining and filtering ---
# df %>% distinct(authyear, .keep_all = T) %>% write.csv(., "../data/vet/authyear.csv")      # see 1_authyear_vetted.xlsx & project notes (Sun Feb  5 06:44:22 EST 2023)
# study <- df %>% distinct(authyear) %>% flatten_chr(); study2 <- df2 %>% distinct(authyear) %>% flatten_chr()  # 544 vs. 557 (checked!)
# setdiff(study2, study)

# ## computer check and multi-entry study summary (including those not in 'fall22check' as well)
# df %>% 
#   distinct(authyear, .keep_all = T) %>% 
#   filter(str_detect(authyear, "/"))                                                     # studies w/ multiple entries (missed Cade10 that has no "/")

Anderson21 <- c("Anderson et al. (2021) (Zone for Dolores Wk28) (part 1/2) (fall22check)",
              "Anderson et al. (2021) (Zone for Dolores Wk28) (part 2/2) (fall22check - new codes)")
Anderson20 <- c("Andersson, 2020 - 1/2 (Sally Week 25) (fall22-check)",
                "Andersson, 2020 - 2/2 (Sally week 25)(fall22-check)")
Arad15 <- c("Arad, 2015 part 1/2 (fall22check -- new codes)",
            "Arad, 2015 part 2/2 (fall22check -- new codes)")
Burke05 <- c("Burke et al., 2005; 2007;2008 COMPLETED part 1/2 (fall22check - new codes)",
             "Burke et al., 2005; 2007;2008 COMPLETED part 2/2 (fall22check - new codes)")
Cade10 <- c("Cade et al., 2010 (rev.) (part 1)(fall22check)",                                 # special one without "/" in label
            "Cade et al., 2010 (rev.) (part 2) (fall22check)")
Elkind20 <- c("Elkind-Hirsch et al., 2020 (Angela week 29; 1/2)",
              "Elkind-Hirsch et al., 2020 (Angela week 29; 2/2)")
Griffin14 <- c("Griffin et al., 2014 (new) (fall22check - new codes 1/2)",
               "Griffin et al., 2014 (new) (fall22check - new codes 2/2)")
Grilo20 <- c("Grilo et al., 2020 (Angela week 29; part 1/2)",
             "Grilo et al., 2020 (Angela week 29; part 2/2)")
Heufelder09 <- c("Heufelder et al., 2009 (Sally week 29) (part 1/2) (fall22check - new codes)",
                 "Heufelder et al., 2009 (Sally week 29) (part 2/2) (fall22check - new codes)")
Jacot20 <- c("Jacot et al., 2020 (Melody, Week 27) (part 1/4) (fall22check)",
             "Jacot et al., 2020 (Melody, Week 27) (part 2/4) (fall22check - new codes)",
             "Jacot et al., 2020 (Melody, Week 27) (part 3/4) (fall22check - new codes)",
             "Jacot et al., 2020 (Melody, Week 27) (part 4/4) (fall22check - new codes)")
Jolly18 <- c("Jolly, 2018 (Completed) (fall22check) part 1/3", 
             "Jolly, 2018 (Completed) (fall22check - new codes) part 2/3",
             "Jolly 2018 (Completed) (fall22check - new codes) part3/3")
Manios08 <- c("Manios et al., 2008 COMPLETED part 1/2 (fall22check - new codes)",
              "Manios et al., 2008 COMPLETED part 2/2 (fall22check - new codes)")
Melanson04 <- c("Melanson, 2004 (completed) (fall22check - new codes) part 1/3",
                "Melanson, 2004 (fall22check - new codes) part 2/3",
                "Melanson, 2004 (fall22check - new codes) part 3/3")                        # --- check MainAux file (done!) Include this will hand MainAux data too
Nilsson01 <- c("Nilsson, 2001 COMPLETED (part 1/2) (fall22check - new codes)",
               "Nilsson, 2001 COMPLETED (part 2/2) (fall22check - new codes)")
Palavras21 <- c("Palavras et al., 2021 (Angela week 28; part 1/2)",
                "Palavras et al., 2021 (Angela week 28; part 2/2)")
Peragallo12 <- c("Peragallo, Gonzalez-Guarda, McCabe &amp; Cianelli, 2012 (updated) (part 1/2) (fall22check)",
               "Peragallo, Gonzalez-Guarda, McCabe &amp; Cianelli, 2012 (updated) (part 2/2) (fall22check - new codes)")
Rongkavilit13 <- c("Rongkavilit et al., 2013 (updated) (part 1/2) (fall22check)",
                 "Rongkavilit et al., 2013 (updated) (part 2/2) (fall22check - new codes)")
Stasinaki21 <- c("Stasinaki et al., 2021 (Angela week 30; part 1/2)",
                 "Stasinaki et al., 2021 (Angela week 30; part 2/2)")
Toobert00 <- c("Toobert et al. 2000 COMPLETED (fall22check - new codes) part 1/2",
               "Toobert et al. 2000 COMPLETED (fall22check - new codes) part 2/2")
Watkins03 <- c("Watkins et al., 2003 COMPLETED part 1/2 (fall22check -- new codes)",
               "Watkins et al., 2003 COMPLETED part 2/2 (fall22check -- new codes)")
WERNER13 <- c("WERNER ET AL. 2013 NEW COMPLETED (fall22check - new codes 1/2)",
              "WERNER ET AL. 2013 NEW COMPLETED (fall22check - new codes 2/2)")
Williams18 <- c("Williams, 2018 (Completed) (fall22check - new codes) part1/3",
                "Williams, 2018 (Completed) (fall22check - new codes) part2/3",
                "Williams 2018 (Completed) (fall22check - new codes) part3/3")

### update sheet1 and sheet2 var info in non-1st entry of multi-entry studies above -------------------------------------------------------------------
## get sheet1 and sheet2 variables
sheet1 <- read_csv("../data/raw/MetaAnalysis_report_2023-01-27_sheet1.csv") %>% 
  rename(authyear = `authyear...1`) %>% 
  select(-`authyear...20`)
sheet2 <- read_csv("../data/raw/MetaAnalysis_report_2023-01-27_sheet2.csv") %>% 
  rename(authyear = `authyear...1`, record = `record...2`) %>% 
  select(-c(`authyear...105`, `record...148`))
var_sheet1 <- names(sheet1)[!grepl("authyear|record", names(sheet1))];
var_sheet2 <- names(sheet2)[!grepl("authyear|record", names(sheet2))]

## update sheet1 variables (both Main and MainAux datasets) ---
study_list <- list(Anderson21, Anderson20, Arad15, Burke05, Cade10, Elkind20, Griffin14, Grilo20, Heufelder09, Jacot20, Jolly18, Manios08,          # for dealing w/ sheet1 (header): study-specific 
                   Melanson04, Nilsson01, Palavras21, Peragallo12, Rongkavilit13, Stasinaki21, Toobert00, Watkins03, WERNER13, Williams18)

for(i in 1:length(study_list)) {                                                                                                                    # update Main data
  study_entries <- study_list[[i]]
  df[which(df$authyear %in% study_entries[-1]), var_sheet1] <- df[which(df$authyear == study_entries[1])[1], var_sheet1]
}
for(i in 1:length(study_list)) {                                                                                                                    # update MainAux data
  study_entries <- study_list[[i]]
  df2[which(df2$authyear %in% study_entries[-1]), var_sheet1] <- df2[which(df2$authyear == study_entries[1])[1], var_sheet1]
}


## update sheet2 variables (Main) ---
before <- lapply(df, function(x){sum(is.na(x))/length(x)})                # log missing% before updating for later checking
study_list_flat <- flatten_chr(study_list)                                                                                                          # for dealing w/ sheet2 (static): group-specific
first_study_entry <- study_list_flat[grepl("1/", study_list_flat)]        # all 1st entries that provide info
all_study_record <- df %>% distinct(authyear, record)

for (i in 1:length(study_list)){
  all_records <- df %>% 
    filter(authyear %in% study_list[[i]]) %>%                             # all existing groups in a given study
    distinct(record) %>% 
    flatten_chr()
  non_first_study_entry <- study_list[[i]][-1]                            # entries needing info in a given study
  
  for (j in 1:length(non_first_study_entry)) {
    for (k in 1:length(all_records)) {
  
      if(length(which(                                                    # verify existence of (authyear, record) combination
                      all_study_record$authyear == non_first_study_entry[j] &
                      all_study_record$record == all_records[k])) == 0) {
        
        next
        
      } else {
        df[which(
                df$authyear == non_first_study_entry[j] & 
                  df$record == all_records[k]), var_sheet2] <- 
                                    df[which(df$authyear == first_study_entry[i] & 
                                      df$record == all_records[k]), var_sheet2][1, ]   # just get one row as updating template
      }
      
    }  # record loop
  }  # entry loop
}  # study loop

# ## check updating
# after <- lapply(df, function(x){sum(is.na(x))/length(x)})                # missing% after updating
# flatten_dbl(before) - flatten_dbl(after); names(df)                      # missing% - var name makes sense



### update sheet2 variables (MainAux) ---
before2 <- lapply(df2, function(x){sum(is.na(x))/length(x)})
all_study_record2 <- df2 %>% distinct(authyear, record)

for (i in 1:length(study_list)){
  all_records <- df2 %>%                                                                #--- (changes)
    filter(authyear %in% study_list[[i]]) %>%                             
    distinct(record) %>% 
    flatten_chr()
  non_first_study_entry <- study_list[[i]][-1]                            
  
  for (j in 1:length(non_first_study_entry)) {
    for (k in 1:length(all_records)) {
  
      if(length(which(                                                    
                      all_study_record2$authyear == non_first_study_entry[j] &          #---
                      all_study_record2$record == all_records[k])) == 0) {              #---
        
        next
        
      } else {
        df2[which(                                                                      #--- 
                df2$authyear == non_first_study_entry[j] &                              #---
                  df2$record == all_records[k]), var_sheet2] <-                         #---  
                                    df2[which(df2$authyear == first_study_entry[i] &    #---
                                      df2$record == all_records[k]), var_sheet2][1, ]   #---
      }
      
    }  
  }  
}  

# ## check updating
# after2 <- lapply(df2, function(x){sum(is.na(x))/length(x)})                # missing% after updating
# flatten_dbl(before2) - flatten_dbl(after2); names(df2)                      # missing% - var name makes sense

write_csv(df, paste0("../data/mid/2_update/Main",rho,".csv"))
write_csv(df2, paste0("../data/mid/2_update/MainAux",rho,".csv"))
```


```{r authyear_combine_filter_inclusion}
######################################################################################################################################################
## This section creates the level-3 index 'study' after combining entries from the same study together
#  - fun_create_study works for both Main and MainAux datasets 
######################################################################################################################################################

dat <- read_csv(paste0("../data/mid/2_update/Main",rho,".csv"))     # ; df <- dat              # copy for comparison 
dat2 <- read_csv(paste0("../data/mid/2_update/MainAux",rho,".csv")) # ; df2 <- dat2

### Step 1: combine multiple entries into the same study -----------------------------------------------------------
## labels for 'study' variable
study_list_name <- as.character(expression(Anderson21, Anderson20, Arad15, Burke05, Cade10, Elkind20, Griffin14, Grilo20, Heufelder09, Jacot20, 
                                           Jolly18, Manios08, Melanson04,Nilsson01, Palavras21, Peragallo12, Rongkavilit13, Stasinaki21, 
                                           Toobert00, Watkins03, WERNER13, Williams18))

fun_create_study <- function(dataset){                         # need study_list from above section !!!
  dataset <- dataset %>% 
    mutate(study = case_when(
     authyear %in% study_list[[1]] ~ study_list_name[1],       # use 'authyear' for filtering studies because 'study' do not have info like 'fall22check'
     authyear %in% study_list[[2]] ~ study_list_name[2],
     authyear %in% study_list[[3]] ~ study_list_name[3],
     authyear %in% study_list[[4]] ~ study_list_name[4],
     authyear %in% study_list[[5]] ~ study_list_name[5],
     authyear %in% study_list[[6]] ~ study_list_name[6],
     authyear %in% study_list[[7]] ~ study_list_name[7],
     authyear %in% study_list[[8]] ~ study_list_name[8],
     authyear %in% study_list[[9]] ~ study_list_name[9],
     authyear %in% study_list[[10]] ~ study_list_name[10],
     authyear %in% study_list[[11]] ~ study_list_name[11],
     authyear %in% study_list[[12]] ~ study_list_name[12],
     authyear %in% study_list[[13]] ~ study_list_name[13],
     authyear %in% study_list[[14]] ~ study_list_name[14],
     authyear %in% study_list[[15]] ~ study_list_name[15],
     authyear %in% study_list[[16]] ~ study_list_name[16],
     authyear %in% study_list[[17]] ~ study_list_name[17],
     authyear %in% study_list[[18]] ~ study_list_name[18],
     authyear %in% study_list[[19]] ~ study_list_name[19],
     authyear %in% study_list[[20]] ~ study_list_name[20],
     authyear %in% study_list[[21]] ~ study_list_name[21],
     authyear %in% study_list[[22]] ~ study_list_name[22],
     T ~ authyear
    ))
  return(dataset)
}
df <- fun_create_study(df)
df2 <- fun_create_study(df2)

### Step 2: filter studies and establish inclusion criteria -------------------------------------------------------------
# ## check the whole list of study for including non-fall22check ones coded from Summer2022
# ## export short list for checking
# df2 %>% 
#   filter(!str_detect(authyear, "fall22check") & 
#            !str_detect(authyear, "fall22-check") & 
#            !str_detect(authyear, "FALL22CHECK")) %>% 
#   filter(!str_detect(authyear, "test") & 
#            !str_detect(authyear, "Test")) %>% 
#   filter(!str_detect(authyear, "EXCLUDE") & 
#            !str_detect(authyear, "Test")) %>% 
#   filter(!str_detect(authyear, "Anand") & 
#            !str_detect(authyear, "Chermack") & 
#            !str_detect(authyear, "Darbes") & 
#            !str_detect(authyear, "Marsiglia et al") &
#            !str_detect(authyear, "Miller") &
#            !str_detect(authyear, "Shaul") &
#            !str_detect(authyear, "Valente et al") & !str_detect(authyear, "Valente et. al.") &
#            !str_detect(authyear, "Wechsberg") &
#            !str_detect(authyear, "Wilson")) %>%   
#   distinct(authyear, .keep_all = T) %>% 
#   relocate(hiv_recnum, drug_recnum, GR1, GR2, GR3, domains, .after = authyear) %>% 
#   write_csv("../data/vet/non_fall22check.csv")

## read in vetted file
Zone_vet <- readxl::read_xlsx("../data/vet/2_non_fall22check_vetted.xlsx", sheet = 1) %>% 
  select(authyear, to_include, hiv_recnum_vet, drug_recnum_vet)

## included studies Zone vetted
Zone_include <- Zone_vet %>% 
  filter(to_include == 1) %>% 
  select(authyear) %>% 
  flatten_chr()

## Ben's exclusion list
Ben_exclude <- c("Jemmott, Jemmott, Fong &amp; Morales, 2010 (updated) (fall22check)",     # Ben: not actually MBX
                 "Mai 2018 (Completed) (fall22-check)",                                    # Ben: not actually MBX
                 "Niiranen, 2014 (fall22check - new codes)",                               # Ben: no rec
                 "Writing group of the PREMIER collaborative research group, 2003 &amp; Lin et al. 2007 COMPLETED (fall22check)")

fun_filter_study <- function(dataset){
  dataset <- dataset %>% 
    filter(str_detect(authyear, "fall22check") | 
             str_detect(authyear, "fall22-check") | 
             str_detect(authyear, "FALL22CHECK") |
             authyear %in% Zone_include) %>% 
    filter(!str_detect(authyear, "exclu") & !str_detect(authyear, "EXCLUDE$")) %>%        # one study (Slade et al. 2020) ends w/ 'EXCLUDE?' and it looks fine 
    filter(!authyear %in% Ben_exclude)                                                    # remove those Ben excluded
  return(dataset)
}

fun_update_recnum <- function(d) {
  d <- d %>% 
    left_join(Zone_vet, by = "authyear") %>% 
    mutate(
      hiv_recnum = case_when(
        to_include == 1 ~ as.numeric(hiv_recnum_vet),
        T ~ hiv_recnum),
      drug_recnum = case_when(
        to_include == 1 ~ as.numeric(drug_recnum_vet),
        T ~ drug_recnum)) %>% 
    select(-c(to_include, hiv_recnum_vet, drug_recnum_vet))
  return(d)
}

df <- df %>%  fun_filter_study() %>% fun_update_recnum()
df2 <- df2 %>%  fun_filter_study() %>% fun_update_recnum()

### Step 3: inclusion criterion -----------------------------------------------------------------------------------------
fun_include_study <- function(dataset){
  dataset <- dataset %>% 
    # distinct(study, .keep_all = T) %>%
    filter((GR2 == 1 & hiv_recnum == 1) | (GR3 == 1 & drug_recnum == 1) | GR1 == 1)         # this criteria may work, even for HIV & AU/DU studies
  return(dataset)
}

df <- fun_include_study(df)
df2 <- fun_include_study(df2) 

# ## check number of studies
# data2have <- dat2 %>% distinct(authyear)
# data2proc <- df2 %>% distinct(study)
# write_csv(data2have, "../data/mid/3_include/study_EScal.csv")       # 557 studies
# write_csv(data2proc, "../data/mid/3_include/study_include.csv")     # 401 studies

# ## save data
# write_csv(df, paste0("../data/mid/3_include/Main",rho,"_include.csv"))
# write_csv(df2, paste0("../data/mid/3_include/MainAux",rho,"_include.csv"))
```


```{r BKUP}
# ## criteria variables
# var: intyn, TWGR, RPRTBHVR, FLUP, designj, hiv_recnum, drug_recnum (INC)

## var description
# fun_table <- function(x){
#   x %>% tabyl() %>% adorn_totals()                                                          # traditional way seems safest
# }
# sink("../table/1_include/study_inclusion_criteria.txt")
# criteria <- df2 %>% 
#   distinct(study, .keep_all = T) %>% 
#   select(study, intyn, TWGR, RPRTBHVR, FLUP, designj, hiv_recnum, drug_recnum, GR1, GR2, GR3) %>% 
#   mutate(across(is.numeric, ~ case_when(
#     .x == -999 ~ NA_real_,
#     .x == -9999 ~ NA_real_,
#     T ~ .x))) 
# criteria %>% select(-study) %>% map(fun_table)
# criteria %>% tabyl(GR1, GR2) 
# criteria %>% tabyl(GR2, GR3)
# criteria %>% tabyl(GR1, GR3) 
# criteria %>% tabyl(GR1, GR2, GR3) 
# criteria %>% tabyl(hiv_recnum, drug_recnum) 
# 
# criteria %>% tabyl(GR2, hiv_recnum)
# criteria %>% tabyl(GR3, drug_recnum) 
# 
# df2 %>% 
#   distinct(study, .keep_all = T) %>% 
#   select(GR2, hiv_recnum) %>% 
#   mutate(across(everything(), ~ case_when(
#     is.na(.x) ~ "missing",
#     .x == -999 ~ "missing",
#     .x == -9999 ~ "missing",
#     T ~ "observed"
#   ))) %>%
#   tabyl(GR2, hiv_recnum)
# 
# df2 %>% 
#   distinct(study, .keep_all = T) %>% 
#   select(GR2, hiv_recnum) %>% 
#   mutate(across(everything(), ~ case_when(
#     is.na(.x) ~ "missing",
#     .x == -999 ~ "missing",
#     .x == -9999 ~ "missing",
#     T ~ as.character(.x)
#   ))) %>%
#   tabyl(GR2, hiv_recnum)
# df2 %>% 
#   distinct(study, .keep_all = T) %>% 
#   select(GR3, drug_recnum) %>% 
#   mutate(across(everything(), ~ case_when(
#     is.na(.x) ~ "missing",
#     .x == -999 ~ "missing",
#     .x == -9999 ~ "missing",
#     T ~ "observed"
#   ))) %>%
#   tabyl(GR3, drug_recnum)
# df2 %>% 
#   distinct(study, .keep_all = T) %>% 
#   select(GR3, drug_recnum) %>% 
#   mutate(across(everything(), ~ case_when(
#     is.na(.x) ~ "missing",
#     .x == -999 ~ "missing",
#     .x == -9999 ~ "missing",
#     T ~ as.character(.x)
#   ))) %>%
#   tabyl(GR3, drug_recnum)
# sink()
```


```{r _____OLD_____data_merge}
## list all datasets and correspondance
df <- read_csv(paste0(get(my_computer), "MBI_master_data.csv"))          # data in 1st submission 
df_new <- read_csv(paste0(new_data_path, "data_Aug2022.csv")) %>%        # Aug 2022 data (ES + FUN_ES)
  select(-c(...1, authyear...235)) %>%
  rename(authyear = authyear...2, record = record.x, 
         INC = INC.x, PRPOS = PRPOS.x, 
         GR1 = GR1.x, GR2 = GR2.x, GR3 = GR3.x, X = X.x)
# df2 <- read_csv(paste0(get(my_computer2), "CompleteES_May2021.csv"))     # Ben's old data (1st submission)
df2 <- read_csv(paste0(get(my_computer2), "CompleteES_May2021_target.csv"))     # Ben's old data (1st submission) + target var
df3 <- read_csv(paste0(get(my_computer2), "CompleteES+Aux_May2021.csv"))        # Ben's old data (1st submission)
df4 <- read_csv(paste0(data_investigate_path, "CompleteES_Aug2022_Aux_r05.csv")) %>%  # Aug 2022 data (ES+Aux + FUN_ES2)
  select(-c(...1, authyear...232)) %>%
  rename(authyear = authyear...2, record = record.x,
         INC = INC.x, PRPOS = PRPOS.x,
         GR1 = GR1.x, GR2 = GR2.x, GR3 = GR3.x, X = X.x)
# df5 <- read_csv(paste0(data_investigate_path, "CompleteES_Aug2022_r05.csv")) %>%   # Aug 2022 data (ES + FUN_ES2) no 'target'
#   select(-c(...1, authyear...232)) %>%
#   rename(authyear = authyear...2, record = record.x, 
#          INC = INC.x, PRPOS = PRPOS.x, 
#          GR1 = GR1.x, GR2 = GR2.x, GR3 = GR3.x, X = X.x)


## find unique studies
studies <- df %>% distinct(authyear) %>% flatten_chr()                # 304
studies2 <- df2 %>% distinct(authyear) %>% flatten_chr()              # 326
studies3 <- df3 %>% distinct(authyear) %>% flatten_chr()              # 331
new_studies <- df_new %>% distinct(authyear) %>% flatten_chr()        # 479
new_studies2 <- df4 %>% distinct(authyear) %>% flatten_chr()          # 488


# ## verify d computation
# # conclusion: the calculations are consistent but new datasets missed some values -> use overlap data from old data
# ind_var <- c("authyear","record","varname","outcomeID","prob_mean","wave_base1")
# verify_d_index <- df %>%
#   select(ind_var) %>%
#   distinct(authyear,record,varname,outcomeID,prob_mean,wave_base1, .keep_all = T)
# d1 <- verify_d_index %>% 
#   left_join(df, by = ind_var) %>%
#   select(ind_var, ES1=d) %>%
#   distinct(authyear,record,varname,outcomeID,prob_mean,wave_base1, .keep_all = T)
# d2 <- verify_d_index %>% 
#   left_join(df2, by = ind_var) %>%
#   select(ind_var, ES2=d) %>%
#   distinct(authyear,record,varname,outcomeID,prob_mean,wave_base1, .keep_all = T)
# d3 <- verify_d_index %>% 
#   left_join(df3, by = ind_var) %>%
#   select(ind_var, ES3=d) %>%
#   distinct(authyear,record,varname,outcomeID,prob_mean,wave_base1, .keep_all = T)
# d4 <- verify_d_index %>% 
#   left_join(df4, by = ind_var) %>%
#   select(ind_var, ES4=d) %>%
#   distinct(authyear,record,varname,outcomeID,prob_mean,wave_base1, .keep_all = T)
# d5 <- verify_d_index %>% 
#   left_join(df_new, by = ind_var) %>%
#   select(ind_var, ES5=d) %>%
#   distinct(authyear,record,varname,outcomeID,prob_mean,wave_base1, .keep_all = T)
# verify_d_data <- d1 %>%
#   left_join(d2, by = ind_var) %>%
#   left_join(d3, by = ind_var) %>%
#   left_join(d4, by = ind_var) %>%
#   left_join(d5, by = ind_var) 


## keep new studies
df_add <- df_new %>% filter(!authyear %in% studies)

# df_add %>% distinct(authyear...2) %>% write_csv(paste0(my_desktop, "study2add.csv"))
studies2add <- read_csv(paste0(new_data_path, "study2add_edited.csv")) %>%
  filter(include == 1) %>% 
  select(authyear) %>%
  flatten_chr()
intersect(studies2add, studies2)     # old Main data 0 overlap w/ new studies -> add new stuides after align var order
intersect(studies2add, studies3)     # old Main+Aux data 0 overlap w/ new studies -> add new stuides after align var order

# c(studies, studies2add) %>% sort() %>% as.tibble %>% write_csv(paste0(my_desktop,"study2include.csv"))
# studies2check <- c(
#   "Gryczynski et al 2021 (Yubo week24)", "Gryczyski et al., 2021 (Wenhao week 25)", 
#   "Williams et al., 2018", "Williams, 2018b",
#   "Williamson et al. 2005 (Adolescents) COMPLETED", "Williamson et al. 2005 (Parents) COMPLETED")
# df_new$reference[which(df_new$authyear...2 %in% studies2check)]
# new_studies <- c(studies, studies2add) %>% 
#   as.tibble() %>%
#   filter(value != "Williams, 2018b")   # duplicate of Williams et al., 2018 (I later checked the supplemental file and the study is valid and included)
df2_add <- df_new %>% filter(authyear %in% studies2add)
df3_add <- df4 %>% filter(authyear %in% studies2add)

## bind datasets
var_main <- intersect(names(df2), names(df_new))     # variable 
var_aux <- intersect(names(df3), names(df4))
variables <- intersect(intersect(names(df2), names(df_new)), intersect(names(df3), names(df4)))

# correspondance: df2 <-> df_new/df2_add; df3 <-> df4/df3_add
setdiff(names(df_new), var_main)        # sd, w9-11, X, X.y (these var can be dropped)
setdiff(names(df2_add), var_main)        # sd, w9-11, X, X.y (these var can be dropped)
setdiff(names(df2), var_main)           # (no difference: add 'authyear.1')
setdiff(names(df3), var_aux)            # (no difference: add 'authyear.1')
setdiff(names(df3_add), var_aux)        # w9-11, X, X.y (these var can be dropped)
setdiff(names(df4), var_aux)            # w9-11, X, X.y (these var can be dropped)

# verify again
setdiff(names(df_new), names(df2))       # Main: sd, w9-11, X, X.y 
setdiff(names(df2), names(df_new))       # Main: authyear.1
setdiff(names(df4), names(df3))          # Main + Aux: w9-11, X, X.y
setdiff(names(df3), names(df4))          # Main + Aux: authyear.1

## select() helps adjust var. order
var_df2 <- df2 %>% colnames()
var_df3 <- df3 %>% colnames()

var_df2_numeric <- df2 %>% select(is.numeric) %>% colnames
var_df3_numeric <- df3 %>% select(is.numeric) %>% colnames

new_df2 <- df2_add %>% 
  mutate(`authyear.1` = authyear, d = as.numeric(d)) %>%
  select(all_of(var_df2)) %>%
  mutate(across(var_df2_numeric, as.numeric)) %>%
  bind_rows(df2) # %>%
  # write_csv(paste0(my_desktop, "new_ES.csv"))
new_df3 <- df3_add %>% 
  mutate(`authyear.1` = authyear, d = as.numeric(d)) %>%
  select(all_of(var_df3)) %>%
  mutate(across(var_df3_numeric, as.numeric)) %>%
  bind_rows(df3) # %>%
  # write_csv(paste0(my_desktop, "new_ES+Aux.csv"))
```


```{r _____OLD_____investigate datasets}
### investigate dataset differences about ES number -------------------------------------------------
## Conclusion: Ben's ES+Aux data seemed based on applying FUN_ES2 to Main+Aux data.
##             my ES+Aux data were processed in "new_data_after_database_update}" in JCCP_v4_data.Rmd
table_new <- df_new %>% filter(authyear %in% studies) %>% tabyl(authyear)
table2 <- df2 %>% filter(authyear %in% studies) %>% tabyl(authyear)
table3 <- df3 %>% filter(authyear %in% studies) %>% tabyl(authyear)
# table4 <- df4 %>% filter(authyear %in% studies) %>% tabyl(authyear)
# rbind(table2, table3, table_new, table4) %>% write_csv("~/Desktop/dat_check2.csv")   # my ES+Aux data: consistent!
table5 <- df5 %>% filter(authyear %in% studies) %>% tabyl(authyear)
rbind(table2, table3, table_new, table5) %>% openxlsx::write.xlsx("~/Desktop/dat_check3.csv")


## investigate dataset differences about stub
var_new <- df_new %>% filter(authyear %in% studies) %>% tabyl(varname)
var2 <- df2 %>% filter(authyear %in% studies) %>% tabyl(varname)
var3 <- df3 %>% filter(authyear %in% studies) %>% tabyl(varname)
# var4 <- df4 %>% filter(authyear %in% studies) %>% tabyl(varname)
# rbind(var2, var3, var_new, var4) %>% write_csv("~/Desktop/var_check2.csv")         # my ES+Aux data: consistent!
var5 <- df5 %>% filter(authyear %in% studies) %>% tabyl(varname)
rbind(var2, var3, var_new, var5) %>% openxlsx::write.xlsx("~/Desktop/var_check3.csv")


## investigate dataset differences about stub category (main vs. aux)
# conclusion: FUN_ES script only generates Main outcomes; FUN_ES2 scripts generates Main and Aux spelled in Capital Letters
# former dataset is a subset of the latter dataset
var_new <- df_new %>% tabyl(varname)
var4 <- df4 %>% tabyl(varname)
rbind(var_new, var4) %>% openxlsx::write.xlsx("~/Desktop/var_check_category.csv")    # my ES+Aux data: consistent!
```


```{r _____OLD_____MBI_data_checking}
## generate study list for MBI data checking among all the coders (10 individuals)
df5 <- read.csv(paste0(my_desktop, "new_ES+Aux.csv"))

## studies w/ NAs on FLUP
list1 <- c("Amaro et al., 2007 (updated)", "Dakof, 2010", "Jolly et al., 2018", "Pedley et al., 2018", "Williams, 2018b")
list0 <- c("Bahromov & Weine, 2011 (updated)", "Lewis et al., 2015 (updated)DUPLICATED", "Lugada et al., 2010 (updated)", "Soares et al., 2014 (new)")
df5 <- df5 %>%
  mutate(
    FLUP = as.numeric(FLUP),
    FLUP = case_when(
    authyear %in% list1 ~ 1,
    authyear %in% list0 ~ 0,
    T ~ FLUP
  )) # %>%
  # filter(FLUP == 1)
 
df5 %>%
  filter(FLUP == 1) %>%
  # filter(is.na(FLUP)) %>%
  distinct(authyear, .keep_all = T) %>%
  select(authyear, reference) %>%
  write_csv(paste0(my_desktop,"study_list_for_checking_6month.csv"))


## investigate the two studies coded by Fan Xuan Chen into PartA (w/ FLUP coding) and PartB (w/o FLUP coding)
a <- df5 %>% filter(authyear == "Pedley et al., 2018") # %>% write_csv(paste0(my_desktop, "Pdeley_et_al.csv"))
b <- df %>% filter(authyear == "Pedley et al., 2018") 
c <- df5 %>% filter(authyear == "Williams, 2018b") # %>% write_csv(paste0(my_desktop, "Williams_2018b.csv"))
d <- df %>% filter(authyear == "Williams, 2018b") 
e <- df5 %>% filter(authyear == "Jolly et al., 2018") # %>% write_csv(paste0(my_desktop, "Jolly_et_al_2018.csv"))
f <- df %>% filter(authyear == "Jolly et al., 2018") 

## check the duration of intervention & timing of 1st posttest
sink(paste0(my_desktop, "intervention_assessment.txt"))
cat("Duration of Intervention\n")
df5 %>% select(dofinter, T1) %>% tabyl(dofinter) %>% adorn_totals()
cat("\n\n\n")
cat("Timing of 1st Followup Assessment\n")
df5 %>% select(dofinter, T1) %>% tabyl(T1) %>% adorn_totals()
sink()

## check FLUP for each domain 
sink(paste0(my_desktop, "FLUP_domain.txt"))
cat("\nLifestyle\n")
df5 %>% distinct(authyear, .keep_all = T) %>% filter(GR1 == 1) %>% tabyl(FLUP) %>% adorn_totals() # LS
cat("\nHIV\n")
df5 %>% distinct(authyear, .keep_all = T) %>% filter(GR2 == 1) %>% tabyl(FLUP) %>% adorn_totals() # HIV
cat("\nAU_DU\n")
df5 %>% distinct(authyear, .keep_all = T) %>% filter(GR3 == 1) %>% tabyl(FLUP) %>% adorn_totals() # AU&DU
sink()

## check FLUP for each domain exclusively (no domain-crossing studies)
df5 <- df5 %>%
  mutate(GRsum = GR1+GR2+GR3)
sink(paste0(my_desktop, "FLUP_domain_exclusive.txt"))
cat("\nDomain Number\n")
df5 %>% distinct(authyear, .keep_all = T) %>% tabyl(GRsum)
cat("\nLifestyle\n")
df5 %>% distinct(authyear, .keep_all = T) %>% filter(GRsum == 1 & GR1 == 1) %>% tabyl(FLUP) %>% adorn_totals() # LS
cat("\nHIV\n")
df5 %>% distinct(authyear, .keep_all = T) %>% filter(GRsum == 1 & GR2 == 1) %>% tabyl(FLUP) %>% adorn_totals() # HIV
cat("\nAU_DU\n")
df5 %>% distinct(authyear, .keep_all = T) %>% filter(GRsum == 1 & GR3 == 1) %>% tabyl(FLUP) %>% adorn_totals() # AD
sink()

## 
df5 %>% distinct(authyear, .keep_all = T) %>% select(c(authyear, authyear.1))
df5 %>% distinct(authyear, authyear.1, .keep_all = T) %>% select(c(authyear, authyear.1)) # 3 extra due to Pedley2018, Jolly2018, and Williams2018b


## randomly assign articles to coders (I later manually adjusted cases where the same coders check their own papers)
# coders <- c("Dolores", "Yubo", "Angela", "Zone", "Wenhao",
#             "Sally", "Marta", "Devlin", "Lydia", "Qijia")
# 
# name <- sample(rep(coders, 43), size = 426, replace = F)
# name %>% as_tibble(c("", name)) %>% write_csv(paste0(my_desktop, 
#                                             "names.csv"))
# name %>% tabyl()
```


```{r _____OLD_____p_value_and_label_issue_in_outcome_coding}
df <- read_csv("~/Desktop/Sheet3_bind_MainAux.csv")
dat <- read.csv("~/Desktop/new_ES+Aux.csv")
df_all_studies <- df %>% distinct(authyear) %>% flatten_chr()
df_studies <- dat %>% distinct(authyear) %>% flatten_chr()

## check number of entered p values
df_ID <- df %>%
  select(authyear)
df2 <- df %>% 
  select(contains("_p_")) %>%
  mutate(across(everything(), as.numeric))
df3 <- df2 %>%
  naniar::replace_with_na_all(condition = ~ abs(.x) > 1)
df4 <- df_ID %>% bind_cols(df3)
df5 <- df4 %>% mutate(across(contains("_p_"), ~ !is.na(.x))) 
df5["number_of_p"] <- rowSums(df5[2:ncol(df5)])


df5 %>% tabyl(number_of_p) %>% adorn_totals()
df5 %>% filter(authyear %in% df_studies) %>% distinct(authyear, .keep_all = T) %>% tabyl(row_sum) %>% adorn_totals()

# df5$authyear[df5$row_sum == 2]

## check label issues 
dat2 <- df %>%
  select(authyear, contains("_type_")) %>%
  mutate(across(everything(), as.character))
dat3 <- tibble()
for(i in 1:length(df_all_studies)){
  dat4 <- dat2 %>%
    filter(authyear == df_all_studies[i]) %>%
    map(~length(unique(.x)))
  dat3 <- dat3 %>%
    bind_rows(dat4)
}  

dat5 <- dat3 %>%
  mutate(authyear = df_all_studies)
dat6 <- dat5[(rowSums(dat5[2:ncol(dat5)]) > (ncol(dat5)-1)), ]
dat7 <- dat6[, (c(TRUE, colSums(dat6[2:ncol(dat6)]) > nrow(dat6)))]
write_csv(dat5, "~/Desktop/entry_label_check_v1.csv")
write_csv(dat7, "~/Desktop/entry_label_check_v2.csv")

```



